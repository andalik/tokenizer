<pre>
                 d8b                          d8,                        
   d8P           ?88                         `8P                         
d888888P          88b                                                    
  ?88'   d8888b   888  d88' d8888b  88bd88b   88bd88888P  d8888b  88bd88b
  88P   d8P' ?88  888bd8P' d8b_,dP  88P' ?8b  88P   d8P' d8b_,dP  88P'  `
  88b   88b  d88 d88888b   88b     d88   88P d88  d8P'   88b     d88     
  `?8b  `?8888P'd88' `?88b,`?888P'd88'   88bd88' d88888P'`?888P'd88'     
                                             by Andalik Industries
</pre>

Tokenizer é um script desenvolvido em Python3 que calcula a quantidade de tokens em um texto ou arquivo de texto nos formatos txt, md ou pdf.

É uma ferramenta útil para verificar se um arquivo pode ser processado integralmente dentro da janela de contexto de uma LLM, ou para determinar a quantidade de tokens em um input ou output, facilitando o cálculo de custos.

![tokenizer](https://github.com/andalik/tokenizer/blob/main/screenshots/tokenizer.png)

## Instalação:

```bash
git clone https://github.com/andalik/tokenizer.git
cd tokenizer
pip install -r requirements.txt
python3 tokenizer.py
```

